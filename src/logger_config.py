import gzip
import json
import logging
import os
import shutil
from datetime import datetime, timezone
from logging.handlers import RotatingFileHandler
from pathlib import Path


class CompressedRotatingFileHandler(RotatingFileHandler):
    """æ”¯æŒå‹ç¼©çš„è½®è½¬æ–‡ä»¶å¤„ç†å™¨"""

    def doRollover(self):
        """æ‰§è¡Œæ—¥å¿—è½®è½¬å¹¶å‹ç¼©æ—§æ–‡ä»¶"""
        if self.stream:
            self.stream.close()
            self.stream = None

        if self.backupCount > 0:
            for i in range(self.backupCount - 1, 0, -1):
                sfn = self.rotation_filename("%s.%d.gz" % (self.baseFilename, i))
                dfn = self.rotation_filename("%s.%d.gz" % (self.baseFilename, i + 1))
                if os.path.exists(sfn):
                    if os.path.exists(dfn):
                        os.remove(dfn)
                    os.rename(sfn, dfn)

            # å‹ç¼©å½“å‰æ—¥å¿—æ–‡ä»¶
            dfn = self.rotation_filename(self.baseFilename + ".1.gz")
            if os.path.exists(dfn):
                os.remove(dfn)

            # å‹ç¼©åŸæ–‡ä»¶
            with open(self.baseFilename, 'rb') as f_in:
                with gzip.open(dfn, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)

            # åˆ é™¤åŸæ–‡ä»¶
            os.remove(self.baseFilename)

        if not self.delay:
            self.stream = self._open()


class OptimizedStructuredFormatter(logging.Formatter):
    """ä¼˜åŒ–çš„ç»“æ„åŒ–æ—¥å¿—æ ¼å¼åŒ–å™¨"""

    MAX_MSG_SIZE = 1024  # å‡å°‘åˆ°1KB

    def format(self, record):
        # æˆªæ–­è¶…å¤§æ¶ˆæ¯
        msg = record.getMessage()
        if len(msg) > self.MAX_MSG_SIZE:
            record.msg = msg[:self.MAX_MSG_SIZE] + "...[TRUNCATED]"

        # ç®€åŒ–çš„æ—¥å¿—ç»“æ„
        log_data = {
            'ts': datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S'),
            'level': record.levelname[0],  # åªä¿ç•™é¦–å­—æ¯
            'msg': record.getMessage(),
            'loc': f"{record.module}:{record.lineno}"
        }

        # åªåœ¨é”™è¯¯æ—¶æ·»åŠ è¯¦ç»†ä¿¡æ¯
        if record.levelno >= logging.ERROR:
            log_data.update({
                'func': record.funcName,
                'thread': record.threadName
            })

        return json.dumps(log_data, ensure_ascii=False, separators=(',', ':'))


def cleanup_old_logs(log_dir, pattern="app_*.log*", max_age_days=7):
    """æ¸…ç†æ—§çš„æ—¥å¿—æ–‡ä»¶"""
    log_path = Path(log_dir)
    if not log_path.exists():
        return

    current_time = datetime.now()
    cleaned_files = []
    total_size_freed = 0

    for log_file in log_path.glob(pattern):
        try:
            file_age = current_time - datetime.fromtimestamp(log_file.stat().st_mtime)
            if file_age.days > max_age_days:
                file_size = log_file.stat().st_size
                log_file.unlink()
                cleaned_files.append(str(log_file))
                total_size_freed += file_size
        except Exception as e:
            print(f"æ¸…ç†æ–‡ä»¶ {log_file} æ—¶å‡ºé”™: {e}")

    if cleaned_files:
        print(f"ğŸ§¹ æ¸…ç†äº† {len(cleaned_files)} ä¸ªæ—§æ—¥å¿—æ–‡ä»¶ï¼Œé‡Šæ”¾ç©ºé—´: {total_size_freed / (1024 * 1024):.2f} MB")
        for file in cleaned_files:
            print(f"  - {file}")


def init_optimized_logger(
        log_dir="logs",
        log_name="app.log",  # å›ºå®šæ–‡ä»¶å
        max_bytes=5 * 1024 * 1024,  # å‡å°‘åˆ°5MB
        backup_count=3,  # å‡å°‘å¤‡ä»½æ•°é‡
        log_level=logging.INFO,
        enable_compression=True,
        cleanup_old=True
):
    """åˆå§‹åŒ–ä¼˜åŒ–çš„æ—¥å¿—ç³»ç»Ÿ"""

    # åˆ›å»ºæ—¥å¿—ç›®å½•
    os.makedirs(log_dir, exist_ok=True)

    # æ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶
    if cleanup_old:
        cleanup_old_logs(log_dir)

    # æ£€æŸ¥ç£ç›˜ç©ºé—´
    try:
        total, used, free = shutil.disk_usage(log_dir)
        free_mb = free / (1024 * 1024)
        if free_mb < 50:  # è‡³å°‘éœ€è¦50MBç©ºé—´
            raise RuntimeError(f"ç£ç›˜ç©ºé—´ä¸è¶³: ä»…å‰© {free_mb:.2f}MB")
    except Exception as e:
        print(f"âš ï¸  ç£ç›˜ç©ºé—´æ£€æŸ¥å¤±è´¥: {e}")

    # é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨
    logger = logging.getLogger()
    logger.handlers.clear()  # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
    logger.setLevel(log_level)

    # åˆ›å»ºä¼˜åŒ–çš„æ ¼å¼åŒ–å™¨
    formatter = OptimizedStructuredFormatter()

    # æ–‡ä»¶å¤„ç†å™¨ - ä½¿ç”¨å›ºå®šæ–‡ä»¶å
    log_path = os.path.join(log_dir, log_name)

    if enable_compression:
        file_handler = CompressedRotatingFileHandler(
            log_path,
            maxBytes=max_bytes,
            backupCount=backup_count,
            encoding='utf-8'
        )
    else:
        file_handler = RotatingFileHandler(
            log_path,
            maxBytes=max_bytes,
            backupCount=backup_count,
            encoding='utf-8'
        )

    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

    # ç®€åŒ–çš„æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_formatter = logging.Formatter(
        '%(asctime)s [%(levelname)s] %(name)s: %(message)s',
        datefmt='%H:%M:%S'
    )
    console_handler.setFormatter(console_formatter)
    logger.addHandler(console_handler)

    # è®¾ç½®æ–‡ä»¶æƒé™
    try:
        os.chmod(log_path, 0o644)
    except Exception:
        pass

    logger.info(f"âœ… ä¼˜åŒ–æ—¥å¿—ç³»ç»Ÿå·²å¯åŠ¨ - æ–‡ä»¶: {log_path}, å¤§å°é™åˆ¶: {max_bytes / (1024 * 1024):.1f}MB")

    return logger


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–ä¼˜åŒ–çš„æ—¥å¿—ç³»ç»Ÿ
    logger = init_optimized_logger(
        log_dir="logs",
        log_name="app.log",
        max_bytes=2 * 1024 * 1024,  # 2MB
        backup_count=3,
        enable_compression=True
    )

    # æµ‹è¯•æ—¥å¿—
    logger.info("åº”ç”¨å¯åŠ¨")
    logger.warning("è¿™æ˜¯ä¸€ä¸ªè­¦å‘Š")
    logger.error("è¿™æ˜¯ä¸€ä¸ªé”™è¯¯")

    print("âœ… æ—¥å¿—ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
